# üìö AI/ML Concepts Explained for Programmers

## **A.0 Overview**
This document explains the key AI/ML concepts used in the PSP Router in programmer-friendly terms. No advanced mathematics required - just practical understanding of how these concepts work in our payment routing system.

---

## üé∞ **A.1 Multi-Armed Bandit: The Slot Machine Problem**

### **What is a Multi-Armed Bandit?**
A multi-armed bandit is a machine learning problem where an agent must choose between multiple actions (arms) to maximize cumulative reward over time. The name comes from slot machines (one-armed bandits) - imagine choosing between multiple slot machines to maximize winnings.

### **Real-World Analogy**
```
You're in a casino with 4 slot machines:
- Machine A: Unknown payout rate
- Machine B: Unknown payout rate  
- Machine C: Unknown payout rate
- Machine D: Unknown payout rate

Goal: Maximize your winnings over 1000 pulls
Challenge: You don't know which machine pays best!
```

### **In PSP Router Context**
```
You have 4 PSPs to choose from:
- Adyen: Unknown success rate
- Stripe: Unknown success rate
- Klarna: Unknown success rate  
- PayPal: Unknown success rate

Goal: Maximize authorization success over time
Challenge: You don't know which PSP works best for each transaction type!
```

### **Key Concepts**
- **Arms**: Available choices (in our case: Adyen, Stripe, Klarna, PayPal)
- **Reward**: Outcome of choosing an arm (authorization success, fee optimization)
- **Exploration vs Exploitation**: Balance between trying new arms vs using known good arms
- **Regret**: Difference between optimal choice and actual choice

---

## üß† **A.2 Epsilon-Greedy Algorithm: The Simple but Effective Approach**

### **What is Epsilon-Greedy?**
Epsilon-greedy is a simple algorithm that balances exploration (trying new options) with exploitation (using known good options). The "epsilon" (Œµ) parameter controls this balance.

### **How It Works**
```csharp
// Simple epsilon-greedy logic
if (random < epsilon)
    return random_arm();  // Explore (Œµ% of time)
else
    return best_known_arm();  // Exploit (1-Œµ% of time)
```

### **Real-World Example**
```
Œµ = 0.1 (10% exploration)

90% of time: Choose Adyen (best known PSP)
10% of time: Randomly try Stripe/Klarna/PayPal

After 100 transactions:
- 90 transactions: Use Adyen (exploitation)
- 10 transactions: Try others (exploration)
```

### **Why It Works**
- **Exploitation**: Uses what you know works
- **Exploration**: Discovers new opportunities
- **Learning**: Updates knowledge after each choice
- **Simple**: Easy to understand and implement

### **In PSP Router**
```csharp
// Configuration
var epsilon = 0.1; // 10% exploration

// Decision logic
if (Random.Shared.NextDouble() < epsilon)
{
    // Explore: Try a random PSP
    return candidates[Random.Shared.Next(candidates.Count)];
}
else
{
    // Exploit: Use the PSP with highest success rate
    return candidates.OrderByDescending(c => c.AuthRate30d).First();
}
```

---

## üé≤ **A.3 Thompson Sampling: The Bayesian Approach**

### **What is Thompson Sampling?**
Thompson Sampling is a more sophisticated approach that uses probability distributions instead of simple averages. It's based on Bayesian statistics and naturally balances exploration and exploitation.

### **How It Works**
```csharp
// Bayesian approach
for each arm:
    sample = beta_distribution(alpha, beta)
    if sample > best_sample:
        best_arm = arm
return best_arm
```

### **Real-World Analogy**
```
Instead of saying "Adyen has 89% success rate"
Thompson Sampling says "Adyen's success rate is probably between 85-93%"

The algorithm samples from this probability distribution
and chooses the arm with the highest sampled value.
```

### **Why It's Better**
- **Uncertainty**: Naturally balances exploration/exploitation based on confidence
- **Adaptive**: More exploration when uncertain, less when confident
- **Bayesian**: Uses probability distributions instead of averages
- **Optimal**: Theoretically optimal for many problems

### **In PSP Router**
```csharp
// Each PSP has a probability distribution
Adyen: Beta(89 successes, 11 failures) ‚Üí Sample: 0.87
Stripe: Beta(78 successes, 22 failures) ‚Üí Sample: 0.82
Klarna: Beta(45 successes, 55 failures) ‚Üí Sample: 0.41

// Choose the PSP with highest sample
return "Adyen" // (0.87 > 0.82 > 0.41)
```

---

## üéØ **A.4 Contextual Bandits: Adding Transaction Context**

### **What is a Contextual Bandit?**
A contextual bandit is a multi-armed bandit that considers additional context (features) when making decisions. Instead of just choosing between arms, it considers the current situation.

### **Traditional vs Contextual Bandits**

**Traditional Bandit:**
```
Segment: "US_USD_Visa"
Decision: Always choose Adyen (89% success rate)
```

**Contextual Bandit:**
```
Segment: "US_USD_Visa"
Context: {amount: 500, risk: 30, sca: true}
Decision: Choose Stripe (better for high-risk SCA transactions)
```

### **Why Context Matters**
```
Same PSP, different contexts:
- Adyen + Low Risk + No SCA = 95% success
- Adyen + High Risk + SCA Required = 70% success

Contextual bandit learns these patterns!
```

### **In PSP Router**
```csharp
// Transaction context
var context = {
    "amount": 150.00m,      // ‚Üí 150.0
    "risk_score": 25,       // ‚Üí 25.0
    "sca_required": true,   // ‚Üí 1.0
    "currency": "USD",      // ‚Üí 0.123 (hash-based)
    "merchant_tier": "premium" // ‚Üí 0.456 (hash-based)
};

// Contextual decision
var decision = bandit.SelectWithContext(segmentKey, candidates, context);
```

---

## üîç **A.5 Semantic Search: Finding Meaning, Not Just Words**

### **What is Semantic Search?**
Semantic search finds relevant information based on meaning, not just exact word matches. It understands the intent behind queries and finds conceptually similar content.

### **Traditional vs Semantic Search**

**Traditional Search (Keyword-based):**
```
Query: "Visa card from US merchant, $200"
Search: Finds exact matches only
Result: No results found
```

**Semantic Search (Meaning-based):**
```
Query: "Visa card from US merchant, $200"
Search: Finds semantically similar transactions
Result: "Visa card from US merchant, $150, routed to Stripe, authorized in 2.3s"
```

### **Why It's Powerful**
- **Flexible**: Finds relevant content even with different wording
- **Intelligent**: Understands context and meaning
- **Comprehensive**: Captures relationships between concepts
- **Human-like**: Mimics how humans search for information

### **In PSP Router**
```csharp
// Query: "Visa card from US merchant, $200"
// Finds similar transactions:
// 1. "Visa card from US merchant, $150, routed to Stripe, authorized in 2.3s" (similarity: 0.95)
// 2. "Visa card from US merchant, $300, routed to Stripe, authorized in 1.8s" (similarity: 0.92)
// 3. "Visa card from US merchant, $100, routed to Adyen, authorized in 3.1s" (similarity: 0.88)
```

---

## üìê **A.6 Cosine Similarity: Measuring Vector Similarity**

### **What is Cosine Similarity?**
Cosine similarity measures how similar two vectors are by calculating the cosine of the angle between them. It's a mathematical way to compare the "direction" of vectors.

### **How It Works**
```
Vector A: [0.1, 0.8, 0.3, 0.2]
Vector B: [0.2, 0.7, 0.4, 0.1]

Cosine Similarity = (A ¬∑ B) / (|A| √ó |B|)
                  = 0.85 (very similar)

Vector C: [0.9, 0.1, 0.8, 0.7]
Cosine Similarity = 0.23 (not similar)
```

### **Why It's Useful**
- **Range**: Always between -1 and 1
- **Direction**: Measures direction, not magnitude
- **Normalized**: Works well with different vector lengths
- **Intuitive**: 1 = identical, 0 = orthogonal, -1 = opposite

### **In PSP Router**
```csharp
// Transaction embeddings
var queryEmbedding = [0.1, 0.8, 0.3, 0.2, ...]; // Current transaction
var lessonEmbedding = [0.2, 0.7, 0.4, 0.1, ...]; // Past transaction

// Calculate similarity
var similarity = CosineSimilarity(queryEmbedding, lessonEmbedding);
// Result: 0.85 (very similar transactions)
```

---

## üß† **A.7 LLM (Large Language Model): The AI Brain**

### **What is an LLM?**
A Large Language Model is an AI system trained on vast amounts of text data that can understand and generate human-like text. In our case, we use GPT-4 to make intelligent routing decisions.

### **How It Works**
```
Input: Transaction context + Historical lessons + PSP candidates
‚Üì
LLM Processing: Analyzes context, considers options, applies reasoning
‚Üì
Output: Structured decision with reasoning
```

### **Why It's Powerful**
- **Context Understanding**: Considers complex relationships
- **Reasoning**: Can explain its decisions
- **Flexibility**: Handles edge cases and new scenarios
- **Learning**: Improves with more context and examples

### **In PSP Router**
```csharp
// LLM receives comprehensive context
var context = {
    Transaction: currentTx,
    Candidates: validCandidates,
    MerchantPreferences: preferences,
    SegmentStats: statistics,
    RelevantLessons: historicalLessons
};

// LLM makes intelligent decision
var decision = await llm.CompleteJsonAsync(systemPrompt, userInstruction, context);
// Result: {"candidate": "Stripe", "reasoning": "Best for high-risk SCA transactions"}
```

---

## üìö **A.8 Bandit Learning Deep Dive**

### A.1 Understanding Multi-Armed Bandits

#### What is a Multi-Armed Bandit?
A multi-armed bandit is a machine learning problem where an agent must choose between multiple actions (arms) to maximize cumulative reward over time. The name comes from slot machines (one-armed bandits) - imagine choosing between multiple slot machines to maximize winnings.

#### Key Concepts
- **Arms**: Available choices (in our case: Adyen, Stripe, Klarna, PayPal)
- **Reward**: Outcome of choosing an arm (authorization success, fee optimization)
- **Exploration vs Exploitation**: Balance between trying new arms vs using known good arms
- **Regret**: Difference between optimal choice and actual choice

### A.2 Bandit Algorithms Explained

#### Epsilon-Greedy Algorithm
```csharp
// Simple epsilon-greedy logic
if (random < epsilon)
    return random_arm();  // Explore (10% of time)
else
    return best_known_arm();  // Exploit (90% of time)
```

**How it works:**
- **Exploration (Œµ%)**: Randomly try different PSPs to learn
- **Exploitation (1-Œµ%)**: Use the PSP with highest success rate
- **Learning**: Update success rates after each transaction

**Example:**
```
Œµ = 0.1 (10% exploration)
- 90% of time: Choose Adyen (best known)
- 10% of time: Randomly try Stripe/Klarna/PayPal
```

#### Thompson Sampling Algorithm
```csharp
// Bayesian approach
for each arm:
    sample = beta_distribution(alpha, beta)
    if sample > best_sample:
        best_arm = arm
return best_arm
```

**How it works:**
- **Bayesian**: Uses probability distributions instead of averages
- **Uncertainty**: Naturally balances exploration/exploitation based on confidence
- **Adaptive**: More exploration when uncertain, less when confident

### A.3 Contextual Bandits: The Game Changer

#### Traditional vs Contextual Bandits

**Traditional Bandit:**
```
Segment: "US_USD_Visa"
Decision: Always choose Adyen (89% success rate)
```

**Contextual Bandit:**
```
Segment: "US_USD_Visa"
Context: {amount: 500, risk: 30, sca: true}
Decision: Choose Stripe (better for high-risk SCA transactions)
```

#### Context Feature Engineering

Our implementation extracts features from transaction context:

```csharp
// Transaction context
var context = {
    "amount": 150.00m,      // ‚Üí 150.0
    "risk_score": 25,       // ‚Üí 25.0
    "sca_required": true,   // ‚Üí 1.0
    "currency": "USD",      // ‚Üí 0.123 (hash-based)
    "merchant_tier": "premium" // ‚Üí 0.456 (hash-based)
};

// Extracted features
var features = {
    "amount": 150.0,
    "risk_score": 25.0,
    "sca_required": 1.0,
    "currency": 0.123,
    "merchant_tier": 0.456
};
```

#### Contextual Scoring Algorithm

```csharp
score = base_success_rate + contextual_bonus

// Base success rate
base_success_rate = total_rewards / total_attempts

// Contextual bonus
contextual_bonus = Œ£(similarity * 0.1)
similarity = 1.0 - |context_value - arm_learned_value|
```

**Example Calculation:**
```
Adyen for "US_USD_Visa":
- Base rate: 0.89
- Learned features: {amount: 200, risk: 20, sca: 0.3}
- Current context: {amount: 150, risk: 25, sca: 1.0}

Similarity calculations:
- amount: 1.0 - |150-200|/max(150,200) = 0.75
- risk: 1.0 - |25-20|/max(25,20) = 0.8
- sca: 1.0 - |1.0-0.3| = 0.3

Contextual bonus: (0.75 + 0.8 + 0.3) * 0.1 = 0.185
Final score: 0.89 + 0.185 = 1.075
```

### A.4 Learning Process Deep Dive

#### 1. Initial State (Cold Start)
```
All PSPs start with no data:
Adyen: {sum: 0, count: 0, features: {}}
Stripe: {sum: 0, count: 0, features: {}}
```

#### 2. First Transactions (Exploration)
```
Transaction 1: $100, risk=10, sca=false
‚Üí Random selection: Adyen
‚Üí Outcome: Success (reward=1.0)
‚Üí Update: Adyen {sum: 1.0, count: 1, features: {amount: 100, risk: 10, sca: 0}}

Transaction 2: $200, risk=30, sca=true  
‚Üí Random selection: Stripe
‚Üí Outcome: Success (reward=0.8) // Lower due to fees
‚Üí Update: Stripe {sum: 0.8, count: 1, features: {amount: 200, risk: 30, sca: 1}}
```

#### 3. Learning Phase (Exploitation with Exploration)
```
Transaction 3: $150, risk=20, sca=false
‚Üí Context: {amount: 150, risk: 20, sca: 0}
‚Üí Adyen score: 1.0 + similarity_bonus = 1.05
‚Üí Stripe score: 0.8 + similarity_bonus = 0.85
‚Üí Choose: Adyen (exploitation)
```

#### 4. Mature Learning (Smart Decisions)
```
After 1000+ transactions:
Adyen: {sum: 850, count: 1000, features: {amount: 180, risk: 15, sca: 0.2}}
Stripe: {sum: 780, count: 1000, features: {amount: 220, risk: 25, sca: 0.6}}

Transaction: $300, risk=40, sca=true
‚Üí Context: {amount: 300, risk: 40, sca: 1}
‚Üí Adyen: 0.85 + low_similarity_bonus = 0.87
‚Üí Stripe: 0.78 + high_similarity_bonus = 0.92
‚Üí Choose: Stripe (contextual decision!)
```

### A.5 Reward Function Design

#### Multi-Factor Reward Calculation
```csharp
reward = base_auth_reward - fee_penalty + speed_bonus - risk_penalty

// Base reward
base_auth_reward = authorized ? 1.0 : 0.0

// Fee penalty (normalized)
fee_penalty = fee_amount / transaction_amount

// Speed bonus
speed_bonus = processing_time < 1000ms ? 0.1 : 0.0

// Risk penalty
risk_penalty = risk_score > 50 ? 0.2 : 0.0

// Clamp to [-1, 1]
final_reward = max(-1.0, min(1.0, reward))
```

#### Example Reward Calculations
```
Transaction 1: $100, authorized=true, fee=$2.30, time=800ms, risk=20
reward = 1.0 - 0.023 + 0.1 - 0.0 = 1.077 ‚Üí 1.0

Transaction 2: $100, authorized=false, fee=$0, time=2000ms, risk=60  
reward = 0.0 - 0.0 + 0.0 - 0.2 = -0.2

Transaction 3: $1000, authorized=true, fee=$20.30, time=1200ms, risk=30
reward = 1.0 - 0.0203 + 0.0 - 0.0 = 0.9797
```

### A.6 Performance Characteristics

#### Convergence Analysis
```
Transactions 1-100:    High exploration, learning patterns
Transactions 100-500:  Balanced exploration/exploitation  
Transactions 500+:     Mostly exploitation, fine-tuning
```

#### Memory Usage
```
Per segment: ~1KB (statistics + features)
1000 segments: ~1MB total
Features per arm: ~100 bytes
```

#### Computational Complexity
```
Selection: O(arms √ó features) = O(4 √ó 10) = O(40) operations
Update: O(features) = O(10) operations
Total: Very fast, suitable for real-time routing
```

### A.7 Advanced Features

#### Feature Decay (Optional Enhancement)
```csharp
// Gradually forget old patterns
foreach (feature in arm_features):
    feature.value = feature.value * 0.99  // 1% decay per update
```

#### Segment Hierarchies (Optional Enhancement)
```csharp
// Learn at multiple levels
Global: All transactions
Country: US transactions  
Currency: US USD transactions
Scheme: US USD Visa transactions
```

#### Confidence Intervals (Optional Enhancement)
```csharp
// Track uncertainty
confidence = 1.0 / sqrt(count)
if confidence > threshold:
    explore_more()
```

### A.8 Comparison with External Libraries

#### VowpalWabbit Advantages
- **Advanced algorithms**: LinUCB, Neural Bandits
- **Feature interactions**: Automatic feature combinations
- **Online learning**: Continuous model updates
- **Industry proven**: Used by major companies

#### Our Implementation Advantages  
- **Customizable**: Easy to modify for PSP routing
- **Lightweight**: No external dependencies
- **Fast**: Optimized for our use case
- **Debuggable**: Full control over algorithm

#### When to Use Each
```
Use Our Implementation When:
- Transaction volume < 1M/day
- Simple feature interactions sufficient
- Need full control over algorithm
- Want minimal dependencies

Use VowpalWabbit When:
- Transaction volume > 1M/day  
- Need advanced ML features
- Complex feature interactions required
- Want industry-standard algorithms
```

### A.9 Monitoring and Debugging

#### Key Metrics to Track
```csharp
// Learning metrics
exploration_rate = exploration_decisions / total_decisions
convergence_rate = change_in_scores / time_period
regret = optimal_reward - actual_reward

// Performance metrics  
auth_rate_by_psp = successes / attempts
fee_optimization = total_fees_saved / total_volume
decision_time = average_routing_time
```

#### Debugging Tools
```csharp
// Log bandit decisions
logger.LogDebug("Bandit selected {PSP} with score {Score} for context {Context}", 
    selectedPSP, score, context);

// Track learning progress
logger.LogInformation("Segment {Segment} learning: {Stats}", 
    segmentKey, armStatistics);
```

---

## üß† **A.9 LLM's Role in PSP Routing: The Intelligent Decision Engine**

### **Primary Function: Intelligent Decision Engine**

The LLM serves as the **brain** of the PSP Router, acting as an expert payment routing consultant that makes complex, context-aware decisions. It's the primary decision maker that considers multiple factors simultaneously and provides reasoning for its choices.

### **Decision Flow: LLM vs Bandit**

```
Transaction Request
        ‚Üì
    [Guardrails] ‚Üê Compliance checks, health status
        ‚Üì
    [LLM Decision] ‚Üê Primary intelligent routing
        ‚Üì
    [Fallback] ‚Üê Bandit learning if LLM fails
        ‚Üì
    [Final Decision]
```

### **LLM Routing Algorithm (Step-by-step)**

1. **Inputs prepared**
   - Valid PSP candidates after guardrails (capabilities, health, SCA) are applied
   - Transaction context, merchant preferences, segment/bandit stats, and vector-memory lessons

2. **Context built for the LLM**
   - Serialize a structured object with: `Transaction`, `Candidates`, `MerchantPreferences`, `SegmentStats`, `RelevantLessons`

3. **Prompting**
   - Construct a strict system prompt with rules and response schema
   - Provide a short user instruction: ‚ÄúRoute this payment‚Ä¶‚Äù

4. **Inference**
   - Call the chat model to produce a JSON decision; tools may be available for health/fee lookups

5. **Validation**
   - Parse JSON to a `RouteDecision`
   - Ensure the chosen `Candidate` is one of the valid PSPs

6. **Return or Fallback**
   - If valid ‚Üí return the decision
   - If missing/invalid ‚Üí return null, triggering deterministic/bandit fallback in the caller

7. **Output**
   - A structured `RouteDecision` with `Candidate`, `Alternates`, `Reasoning`, `Guardrail`, `Constraints`, and `Features_Used`

#### Code entry points
- `PspRouter.DecideAsync(...)` orchestrates LLM-first with fallback
- `PspRouter.DecideWithLLMAsync(...)` builds context, prompts, calls the model, validates
- `PspRouter.GetRelevantLessonsAsync(...)` integrates vector memory (stubbed pending embeddings)
- `PspRouter.BuildSystemPrompt()` defines the strict schema and rules

### **What the LLM Receives**

The LLM gets comprehensive context for each decision:

```json
{
  "Transaction": {
    "MerchantId": "M123",
    "Amount": 150.00,
    "Currency": "USD", 
    "Method": "Card",
    "Scheme": "Visa",
    "SCARequired": false,
    "RiskScore": 18
  },
  "Candidates": [
    {
      "Name": "Adyen",
      "Health": "green",
      "AuthRate30d": 0.89,
      "FeeBps": 200,
      "Supports3DS": true
    }
  ],
  "MerchantPreferences": {
    "prefer_low_fees": "true"
  },
  "SegmentStats": {
    "Adyen_USD_Visa_auth": 0.89,
    "Stripe_USD_Visa_auth": 0.87
  },
  "RelevantLessons": [
    "USD Visa transactions work well with Adyen for low-risk merchants"
  ]
}
```

### **LLM's Decision Process**

#### **1. Context Analysis**
- Transaction characteristics (amount, risk, currency, method)
- PSP capabilities and real-time health status
- Merchant preferences and business rules
- Historical performance data from bandit learning
- Relevant lessons from vector memory

#### **2. Business Logic Application**
- **Compliance Enforcement**: SCA/3DS requirements, payment method support
- **Health Checks**: Only routes to healthy PSPs
- **Preference Handling**: Considers merchant fee vs auth rate preferences
- **Risk Management**: Applies risk-based routing rules

#### **3. Intelligent Reasoning**
The LLM can handle complex scenarios like:
- "High-risk transaction needs 3DS support"
- "Merchant prefers low fees, but auth rate is more important for this amount"
- "Historical data shows Stripe performs better for SCA transactions"
- "Weekend transactions have different patterns"

#### **4. Structured Decision Output**
```json
{
  "Candidate": "Stripe",
  "Reasoning": "Chose Stripe over Adyen because: 1) Transaction requires SCA and Stripe has better 3DS performance, 2) Historical data shows 3% higher auth rate for SCA transactions, 3) Fee difference is minimal for this amount",
  "Features_Used": ["sca_required=true", "auth_rate=0.87", "fee_bps=200"]
}
```

### **Advanced LLM Capabilities**

#### **Tool Calling for Real-Time Data**
```csharp
// LLM can call external APIs for current information
var tools = new List<IAgentTool>
{
    new GetHealthTool(health),      // Get current PSP health status
    new GetFeeQuoteTool(fees, tx)   // Get real-time fee quotes
};
```

#### **Memory Integration**
```csharp
// LLM uses vector memory for contextual lessons
var lessons = await GetRelevantLessonsAsync(ctx, ct);
// Example: "Similar transactions: Adyen failed for high-risk SCA, Stripe succeeded"
```

#### **Complex Scenario Handling**
The LLM excels at handling edge cases:
- **Compliance Conflicts**: "Merchant has 3D Secure preference but transaction is low-risk"
- **Trade-off Analysis**: "Fee difference is $0.50 but auth rate difference is 5%"
- **Temporal Patterns**: "Historical data shows weekend transactions perform differently"
- **Multi-factor Decisions**: Balancing auth rates, fees, compliance, and preferences

### **LLM vs Bandit: When Each is Used**

#### **LLM is Primary When:**
- ‚úÖ **Complex context** needs analysis
- ‚úÖ **Business rules** must be applied
- ‚úÖ **Compliance** requirements exist
- ‚úÖ **Merchant preferences** matter
- ‚úÖ **Historical lessons** are relevant
- ‚úÖ **Edge cases** need expert reasoning

#### **Bandit is Fallback When:**
- ‚ö†Ô∏è **LLM is unavailable** (API failure, timeout)
- ‚ö†Ô∏è **LLM response is invalid** (parsing error)
- ‚ö†Ô∏è **Simple scenarios** where bandit is sufficient
- ‚ö†Ô∏è **High-volume** transactions where speed matters

### **Learning Integration**

#### **1. Feeds Bandit Learning**
```csharp
// LLM decisions become training data for bandit
var outcome = ProcessTransaction(decision);
router.UpdateReward(decision, outcome); // Updates bandit statistics
```

#### **2. Learns from Bandit Data**
```csharp
// LLM uses bandit statistics in its decisions
"SegmentStats": {
    "Adyen_USD_Visa_auth": 0.89,  // From bandit learning
    "Stripe_USD_Visa_auth": 0.87
}
```

#### **3. Creates Memory Lessons**
```csharp
// LLM decisions become lessons for future use
var lesson = $"Transaction {tx.Amount} {tx.Currency}: {decision.Candidate} succeeded because {decision.Reasoning}";
await memory.AddAsync(lesson, embedding);
```

### **Real-World Example**

#### **Scenario**: $500 USD Visa, risk=40, SCA required, merchant prefers low fees

**LLM's Analysis:**
```
1. Compliance: SCA required ‚Üí Need 3DS support
2. Context: High amount + high risk + SCA = complex scenario  
3. Preferences: Low fees vs auth success trade-off
4. History: "High-risk SCA transactions: Stripe 92% vs Adyen 85%"
5. Reasoning: "Fee difference is $2.50, but auth rate difference is 7%"
6. Decision: Choose Stripe (auth success more valuable than fee savings)
```

**LLM Response:**
```json
{
  "Candidate": "Stripe",
  "Reasoning": "Selected Stripe for high-risk SCA transaction. While Adyen has lower fees ($2.50 difference), Stripe's 7% higher auth rate for SCA transactions provides better overall value. Historical data shows 92% vs 85% success rate for similar transactions.",
  "Features_Used": ["sca_required=true", "risk_score=40", "amount=500", "auth_rate=0.92"]
}
```

### **System Prompt Engineering**

The LLM uses a carefully crafted system prompt that defines its role:

```
You are an expert payment service provider (PSP) routing system. Your job is to select the optimal PSP for each transaction to maximize authorization success, minimize fees, and ensure compliance.

CRITICAL RULES:
1. NEVER route to a PSP that doesn't support the payment method
2. ALWAYS enforce SCA/3DS requirements when specified
3. Consider authorization rates, fees, and merchant preferences
4. Use historical lessons to inform decisions
5. Provide clear reasoning for your choice

DECISION FACTORS (in order of importance):
1. Compliance (SCA/3DS requirements)
2. Authorization success rates
3. Fee optimization
4. Merchant preferences
5. Historical performance
```

### **Summary: LLM's Value**

The LLM transforms the PSP Router from a simple statistical system into an **intelligent payment expert** that:

1. **üß† Thinks**: Analyzes complex scenarios with multiple factors
2. **üìã Applies Rules**: Enforces compliance and business logic
3. **üìö Learns**: Uses historical lessons and bandit data
4. **üîß Adapts**: Handles edge cases and complex scenarios
5. **üìä Explains**: Provides clear reasoning for decisions
6. **üõ°Ô∏è Ensures Safety**: Fallback to bandit when needed

This makes the system capable of handling real-world payment routing scenarios that require expert-level decision making.

## üß† **A.10 Vector Database: The System's Memory**

### **Role and Purpose**
The vector database serves as the **"memory" of the PSP Router system**, providing the LLM with historical context and lessons learned from past routing decisions. It acts like a human expert's experience - when making a routing decision, the system can recall similar past situations and their outcomes to make more informed choices.

### **How It Works**

#### **1. Learning Phase (After Each Transaction)**
```
Transaction Outcome ‚Üí Generate Embedding ‚Üí Store in Vector DB
```
- **Captures Lessons**: After each transaction completes, the system captures the outcome
- **Creates Embeddings**: Uses OpenAI embeddings to convert the transaction context and outcome into a vector representation
- **Stores Knowledge**: Saves the embedding along with metadata (PSP used, success/failure, fees, etc.) in PostgreSQL with pgvector

#### **2. Decision Phase (During Routing)**
```
New Transaction ‚Üí Generate Query Embedding ‚Üí Search Similar Contexts ‚Üí Retrieve Lessons ‚Üí Provide to LLM
```
- **Query Generation**: Creates an embedding for the current transaction context
- **Semantic Search**: Finds similar past transactions using cosine similarity
- **Lesson Retrieval**: Returns the most relevant historical lessons
- **LLM Enhancement**: Provides these lessons as context to the LLM for better decision-making

### **Key Benefits**

#### **üß† Human-Like Decision Making**
- **Pattern Recognition**: Identifies patterns in successful/failed transactions
- **Contextual Learning**: Learns from similar situations (same merchant, country, payment method, etc.)
- **Experience Accumulation**: Builds institutional knowledge over time

#### **üìà Continuous Improvement**
- **Adaptive Learning**: System gets smarter with each transaction
- **Historical Insights**: Leverages months/years of routing experience
- **Contextual Awareness**: Considers nuanced factors that simple rules might miss

#### **üéØ Enhanced Accuracy**
- **Better Decisions**: LLM makes more informed choices with historical context
- **Reduced Errors**: Avoids repeating past mistakes
- **Optimized Routing**: Learns which PSPs work best in specific scenarios

### **Technical Implementation**

#### **Database Schema**
```sql
CREATE TABLE psp_lessons (
    key TEXT PRIMARY KEY,
    content TEXT NOT NULL,           -- Transaction context and outcome
    meta JSONB NOT NULL,             -- Metadata (PSP, fees, success, etc.)
    embedding vector(3072)           -- OpenAI embedding vector
);
```

#### **Search Process**
```csharp
// 1. Generate query embedding
var query = $"PSP routing for {currency} {method} {scheme} merchant {country}";
var queryEmbedding = await embeddings.CreateEmbeddingAsync(query, ct);

// 2. Search for similar contexts
var results = await memory.SearchAsync(queryEmbedding, k: 5, ct);

// 3. Provide lessons to LLM
var contextJson = JsonSerializer.Serialize(new {
    Transaction = currentTx,
    Candidates = validCandidates,
    RelevantLessons = results.Select(r => r.text).ToList()  // Historical insights
});
```

### **Vector Memory Flow**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Transaction   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Generate       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Store in      ‚îÇ
‚îÇ   Outcome       ‚îÇ    ‚îÇ   Embedding      ‚îÇ    ‚îÇ   pgvector      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                        ‚îÇ
                                                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Retrieve      ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Semantic       ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Query         ‚îÇ
‚îÇ   Lessons       ‚îÇ    ‚îÇ   Search         ‚îÇ    ‚îÇ   Similar       ‚îÇ
‚îÇ   Learned       ‚îÇ    ‚îÇ   (Cosine)       ‚îÇ    ‚îÇ   Contexts      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                        ‚îÇ
        ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Apply         ‚îÇ    ‚îÇ   Contextual     ‚îÇ
‚îÇ   Insights      ‚îÇ    ‚îÇ   Knowledge      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Important Distinction**
- **Vector DB is FOR the LLM**: Used exclusively to enhance LLM decision-making, not for the bandit calculations (until next stages, see below)
- **Memory vs. Logic**: Vector DB provides historical context, not routing logic

### **Future Usage (Next Stages)**
- **Bandit Recovery**: Vector DB will also store transaction outcomes for bandit statistics recovery at startup
- **Dual Purpose**: Vector DB will serve both LLM context AND bandit learning persistence
- **Startup Recovery**: System will rebuild bandit statistics from stored transaction outcomes in vector DB
- **Learning Continuity**: Ensures bandit learning progress is preserved across server restarts

## üß† **A.11 OpenAI Embeddings: The Magic Behind Semantic Search**

### **What are OpenAI Embeddings?**
OpenAI embeddings are **numerical representations of text** that capture semantic meaning. They convert words, sentences, or documents into high-dimensional vectors (arrays of numbers) that can be used for similarity comparisons and semantic search.

### **How They Work**
```
Text Input ‚Üí OpenAI API ‚Üí Vector Output (array of numbers)
"Payment routing for Visa cards" ‚Üí [0.1, -0.3, 0.8, 0.2, ...] (3072 numbers)
```

### **Key Properties**

#### **üéØ Semantic Similarity**
- **Similar texts** produce **similar vectors**
- **Different texts** produce **different vectors**
- **Meaning matters more than exact words**

#### **üìä Dimensionality**
- **OpenAI embeddings**: 3072 dimensions (numbers) for `text-embedding-3-large`
- **Each dimension** represents some aspect of meaning
- **High-dimensional space** allows for nuanced representations

#### **üî¢ Mathematical Operations**
- **Cosine similarity**: Measure how similar two texts are
- **Vector arithmetic**: Can find relationships between concepts
- **Distance calculations**: Find nearest neighbors in meaning space

### **Real-World Example in PSP Router**

#### **Scenario: Learning from Past Transactions**

**1. Store a Lesson**
```csharp
// After a successful transaction
var lesson = "Visa card from US merchant, $150, routed to Stripe, authorized in 2.3s";
var embedding = await embeddings.CreateEmbeddingAsync(lesson, ct);
await memory.AddAsync("lesson_001", lesson, metadata, embedding, ct);
```

**2. Search for Similar Contexts**
```csharp
// New transaction: "Visa card from US merchant, $200"
var query = "Visa card from US merchant, $200";
var queryEmbedding = await embeddings.CreateEmbeddingAsync(query, ct);
var results = await memory.SearchAsync(queryEmbedding, k: 3, ct);

// Results might include:
// 1. "Visa card from US merchant, $150, routed to Stripe, authorized in 2.3s" (similarity: 0.95)
// 2. "Visa card from US merchant, $300, routed to Stripe, authorized in 1.8s" (similarity: 0.92)
// 3. "Visa card from US merchant, $100, routed to Adyen, authorized in 3.1s" (similarity: 0.88)
```

**3. Provide Context to LLM**
```csharp
var contextJson = JsonSerializer.Serialize(new {
    Transaction = currentTx,
    Candidates = validCandidates,
    RelevantLessons = results.Select(r => r.text).ToList()
    // LLM gets: "Based on similar past transactions, Stripe has been successful for US Visa cards"
});
```

### **Why Embeddings are Game-Changing**

#### **Traditional Approach (Exact Matching)**
```
Query: "Visa card from US merchant, $200"
Search: Only finds exact matches
Result: No results found
```

#### **Embedding Approach (Semantic Matching)**
```
Query: "Visa card from US merchant, $200"
Search: Finds semantically similar transactions
Result: "Visa card from US merchant, $150, routed to Stripe, authorized in 2.3s"
```

### **Benefits for PSP Router**

1. **üß† Semantic Understanding**: Finds relevant lessons even with different wording
2. **üìà Contextual Learning**: Learns from similar situations, not just exact matches
3. **üîç Pattern Recognition**: Identifies successful routing patterns across different scenarios
4. **üöÄ Continuous Improvement**: System gets smarter as it accumulates more lessons
5. **üë®‚Äçüíº Human-Like Reasoning**: Mimics how human experts recall similar past experiences

### **Technical Implementation**

#### **OpenAI Embedding Models**
- **text-embedding-3-large**: 3072 dimensions (used in PSP Router)
- **text-embedding-3-small**: 1536 dimensions
- **text-embedding-ada-002**: 1536 dimensions (older model)

#### **Database Storage**
```sql
CREATE TABLE psp_lessons (
    key TEXT PRIMARY KEY,
    content TEXT NOT NULL,           -- Original text
    meta JSONB NOT NULL,             -- Metadata
    embedding vector(3072)           -- OpenAI embedding vector
);
```

#### **Similarity Search**
```sql
-- Find most similar lessons using cosine similarity
SELECT content, meta, 1 - (embedding <=> @query_embedding) AS similarity
FROM psp_lessons
ORDER BY embedding <=> @query_embedding
LIMIT 5;
```

### **In Summary**
OpenAI embeddings are the **"translation layer"** that converts human language into mathematical representations that computers can understand and compare. In the PSP Router, they enable the system to find relevant historical lessons based on meaning, not just exact text matches - making the routing decisions much more intelligent and contextually aware! üß†‚ú®

---

## üéØ **Summary**

This document has covered the key AI/ML concepts used in the PSP Router:

1. **üé∞ Multi-Armed Bandits**: The foundation for learning optimal PSP selection
2. **üß† Epsilon-Greedy**: Simple but effective exploration/exploitation balance
3. **üé≤ Thompson Sampling**: Bayesian approach for sophisticated decision making
4. **üéØ Contextual Bandits**: Adding transaction context for smarter decisions
5. **üîç Semantic Search**: Finding relevant lessons based on meaning
6. **üìê Cosine Similarity**: Measuring vector similarity for semantic search
7. **üß† LLM**: The AI brain that makes intelligent routing decisions
8. **üìö Bandit Learning**: Deep dive into how the learning system works
9. **üß† LLM's Role**: Detailed explanation of how LLM serves as the intelligent decision engine
10. **üß† Vector Database**: The system's memory for storing and retrieving historical lessons
11. **üß† OpenAI Embeddings**: The magic behind semantic search and vector similarity

These concepts work together to create an intelligent payment routing system that learns from experience and makes increasingly better decisions over time! üöÄ
